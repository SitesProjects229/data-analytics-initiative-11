import { SRGBColorSpace, VideoTexture } from "three/webgpu";
import { float, max, min, or, screenUV, select, step, texture, uniform, vec2, vec4, viewportSize } from "three/tsl";
const componentDefinition = {
	name: "WebcamTexture",
	category: "Base Layers",
	description: "Display a live webcam feed with customizable object-fit modes",
	props: {
		objectFit: {
			default: "cover",
			description: "How the webcam feed should be sized within the viewport",
			transform: (value) => {
				return {
					"cover": 0,
					"contain": 1,
					"fill": 2,
					"scale-down": 3,
					"none": 4
				}[value] ?? 0;
			},
			ui: {
				type: "select",
				options: [
					{
						label: "Cover",
						value: "cover"
					},
					{
						label: "Contain",
						value: "contain"
					},
					{
						label: "Fill",
						value: "fill"
					},
					{
						label: "Scale Down",
						value: "scale-down"
					},
					{
						label: "None",
						value: "none"
					}
				],
				label: "Object Fit"
			}
		},
		mirror: {
			default: true,
			description: "Mirror the webcam feed horizontally (selfie mode)",
			ui: {
				type: "checkbox",
				label: "Mirror"
			}
		}
	},
	fragmentNode: ({ uniforms, onCleanup }) => {
		const baseUV = screenUV;
		let mediaStream = null;
		let videoElement = null;
		let videoTexture = null;
		let isInitialized = false;
		let isDisposed = false;
		const videoAspectUniform = uniform(1);
		const videoWidthUniform = uniform(640);
		const videoHeightUniform = uniform(480);
		const placeholderVideo = document.createElement("video");
		placeholderVideo.playsInline = true;
		placeholderVideo.muted = true;
		videoTexture = new VideoTexture(placeholderVideo);
		videoTexture.colorSpace = SRGBColorSpace;
		const textureNode = texture(videoTexture);
		const startWebcam = async () => {
			if (isInitialized || isDisposed) return;
			try {
				mediaStream = await navigator.mediaDevices.getUserMedia({
					video: {
						width: { ideal: 1280 },
						height: { ideal: 720 },
						facingMode: "user"
					},
					audio: false
				});
				if (isDisposed) {
					mediaStream.getTracks().forEach((track) => track.stop());
					mediaStream = null;
					return;
				}
				videoElement = document.createElement("video");
				videoElement.srcObject = mediaStream;
				videoElement.playsInline = true;
				videoElement.muted = true;
				await new Promise((resolve, reject) => {
					if (!videoElement) return reject(/* @__PURE__ */ new Error("Video element not created"));
					videoElement.onloadedmetadata = () => {
						resolve();
					};
					videoElement.onerror = () => {
						reject(/* @__PURE__ */ new Error("Failed to load video metadata"));
					};
				});
				if (isDisposed) return;
				await videoElement.play();
				if (isDisposed) return;
				const width = videoElement.videoWidth || 640;
				const height = videoElement.videoHeight || 480;
				videoAspectUniform.value = width / height;
				videoWidthUniform.value = width;
				videoHeightUniform.value = height;
				if (videoTexture) videoTexture.dispose();
				videoTexture = new VideoTexture(videoElement);
				videoTexture.colorSpace = SRGBColorSpace;
				textureNode.value = videoTexture;
				isInitialized = true;
				console.log(`[WebcamTexture] Webcam started: ${width}x${height}`);
			} catch (error) {
				if (error instanceof DOMException) if (error.name === "NotAllowedError") console.error("[WebcamTexture] Camera permission denied by user");
				else if (error.name === "NotFoundError") console.error("[WebcamTexture] No camera found on this device");
				else if (error.name === "NotReadableError") console.error("[WebcamTexture] Camera is already in use by another application");
				else console.error("[WebcamTexture] Camera error:", error.message);
				else console.error("[WebcamTexture] Failed to start webcam:", error);
			}
		};
		startWebcam();
		onCleanup(() => {
			isDisposed = true;
			if (mediaStream) {
				mediaStream.getTracks().forEach((track) => track.stop());
				mediaStream = null;
			}
			if (videoTexture) {
				videoTexture.dispose();
				videoTexture = null;
			}
			if (videoElement) {
				videoElement.srcObject = null;
				videoElement = null;
			}
			placeholderVideo.srcObject = null;
			isInitialized = false;
		});
		const uv$1 = baseUV;
		const viewportAspect = viewportSize.x.div(viewportSize.y);
		const objectFitMode = uniforms.objectFit.uniform;
		const coverScale = max(viewportAspect.div(videoAspectUniform), float(1));
		const coverUVScale = vec2(videoAspectUniform.div(viewportAspect).mul(coverScale), coverScale);
		const containScale = min(viewportAspect.div(videoAspectUniform), float(1));
		const containUVScale = vec2(videoAspectUniform.div(viewportAspect).mul(containScale), containScale);
		const fillUVScale = vec2(1, 1);
		const scaleDownScale = min(min(viewportAspect.div(videoAspectUniform), float(1)), min(viewportSize.x.div(videoWidthUniform), viewportSize.y.div(videoHeightUniform)));
		const scaleDownUVScale = vec2(videoAspectUniform.div(viewportAspect).mul(scaleDownScale), scaleDownScale);
		const noneScale = min(viewportSize.x.div(videoWidthUniform), viewportSize.y.div(videoHeightUniform));
		const noneUVScale = vec2(videoAspectUniform.div(viewportAspect).mul(noneScale), noneScale);
		const isCover = step(objectFitMode, float(.5));
		const isContain = step(float(.5), objectFitMode).mul(step(objectFitMode, float(1.5)));
		const isFill = step(float(1.5), objectFitMode).mul(step(objectFitMode, float(2.5)));
		const isScaleDown = step(float(2.5), objectFitMode).mul(step(objectFitMode, float(3.5)));
		const isNone = step(float(3.5), objectFitMode);
		const uvScale = vec2(0).add(coverUVScale.mul(isCover)).add(containUVScale.mul(isContain)).add(fillUVScale.mul(isFill)).add(scaleDownUVScale.mul(isScaleDown)).add(noneUVScale.mul(isNone));
		const adjustedUV = uv$1.sub(vec2(.5)).div(uvScale).add(vec2(.5));
		const mirrorMode = uniforms.mirror.uniform;
		const finalUV = vec2(select(mirrorMode, float(1).sub(adjustedUV.x), adjustedUV.x), float(1).sub(adjustedUV.y));
		const sampledColor = textureNode.sample(finalUV);
		const isOutOfBounds = or(or(finalUV.x.lessThan(0), finalUV.x.greaterThan(1)), or(finalUV.y.lessThan(0), finalUV.y.greaterThan(1)));
		return vec4(sampledColor.rgb, select(isOutOfBounds, float(0), sampledColor.a));
	}
};
var WebcamTexture_default = componentDefinition;
export { componentDefinition as n, WebcamTexture_default as t };
